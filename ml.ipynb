{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9429641a-6981-48eb-ba7c-7de316281c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras_tuner as kt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34086d51-864a-495e-881f-da0e5091f105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Faction</th>\n",
       "      <th>Class</th>\n",
       "      <th>KB</th>\n",
       "      <th>D</th>\n",
       "      <th>HK</th>\n",
       "      <th>DD</th>\n",
       "      <th>HD</th>\n",
       "      <th>Honor</th>\n",
       "      <th>Win</th>\n",
       "      <th>Lose</th>\n",
       "      <th>Rol</th>\n",
       "      <th>BE</th>\n",
       "      <th>Class Type</th>\n",
       "      <th>Pets</th>\n",
       "      <th>Armor Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Alliance</td>\n",
       "      <td>Death Knight</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>125000</td>\n",
       "      <td>36936</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Melee</td>\n",
       "      <td>1</td>\n",
       "      <td>Plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>Horde</td>\n",
       "      <td>Shaman</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>14851</td>\n",
       "      <td>92428</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>heal</td>\n",
       "      <td>1</td>\n",
       "      <td>Both</td>\n",
       "      <td>0</td>\n",
       "      <td>Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Horde</td>\n",
       "      <td>Mage</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>102000</td>\n",
       "      <td>16791</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Ranged</td>\n",
       "      <td>0</td>\n",
       "      <td>Cloth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>Horde</td>\n",
       "      <td>Death Knight</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>84194</td>\n",
       "      <td>34559</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Melee</td>\n",
       "      <td>1</td>\n",
       "      <td>Plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>Alliance</td>\n",
       "      <td>Demon Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>89847</td>\n",
       "      <td>6296</td>\n",
       "      <td>781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Melee</td>\n",
       "      <td>0</td>\n",
       "      <td>Leather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Horde</td>\n",
       "      <td>Mage</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>25932</td>\n",
       "      <td>2574</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Ranged</td>\n",
       "      <td>0</td>\n",
       "      <td>Cloth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>Horde</td>\n",
       "      <td>Death Knight</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>90874</td>\n",
       "      <td>34388</td>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Melee</td>\n",
       "      <td>1</td>\n",
       "      <td>Plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>Alliance</td>\n",
       "      <td>Demon Hunter</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>85229</td>\n",
       "      <td>17286</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Melee</td>\n",
       "      <td>0</td>\n",
       "      <td>Leather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>Horde</td>\n",
       "      <td>Rogue</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14925</td>\n",
       "      <td>946</td>\n",
       "      <td>413</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dps</td>\n",
       "      <td>1</td>\n",
       "      <td>Melee</td>\n",
       "      <td>0</td>\n",
       "      <td>Leather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4158</th>\n",
       "      <td>Horde</td>\n",
       "      <td>Death Knight</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>32887</td>\n",
       "      <td>24753</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dps</td>\n",
       "      <td>0</td>\n",
       "      <td>Melee</td>\n",
       "      <td>1</td>\n",
       "      <td>Plate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Faction         Class  KB  D  HK      DD     HD  Honor  Win  Lose  \\\n",
       "1941  Alliance  Death Knight   7  7  35  125000  36936    580    1     0   \n",
       "2334     Horde        Shaman   1  4  34   14851  92428    351    0     1   \n",
       "2004     Horde          Mage   2  4  42  102000  16791    271    0     1   \n",
       "2884     Horde  Death Knight   3  5  32   84194  34559    555    1     0   \n",
       "3820  Alliance  Demon Hunter   1  0  31   89847   6296    781    1     0   \n",
       "870      Horde          Mage   0  5  34   25932   2574    500    1     0   \n",
       "1808     Horde  Death Knight   4  5  26   90874  34388    513    1     0   \n",
       "4878  Alliance  Demon Hunter   4  2  25   85229  17286    294    0     1   \n",
       "2194     Horde         Rogue   2  1  11   14925    946    413    1     0   \n",
       "4158     Horde  Death Knight   1  3  33   32887  24753    520    1     0   \n",
       "\n",
       "       Rol  BE Class Type  Pets Armor Type  \n",
       "1941   dps   0      Melee     1      Plate  \n",
       "2334  heal   1       Both     0       Mail  \n",
       "2004   dps   0     Ranged     0      Cloth  \n",
       "2884   dps   0      Melee     1      Plate  \n",
       "3820   dps   0      Melee     0    Leather  \n",
       "870    dps   0     Ranged     0      Cloth  \n",
       "1808   dps   0      Melee     1      Plate  \n",
       "4878   dps   0      Melee     0    Leather  \n",
       "2194   dps   1      Melee     0    Leather  \n",
       "4158   dps   0      Melee     1      Plate  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_to_ml.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a12497-e12b-4199-b41f-45cf115d853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Faction', axis=1)\n",
    "y = df['Faction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_columns = ['Class', 'Rol', 'Class Type', 'Armor Type']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_columns])\n",
    "X_test_encoded = encoder.transform(X_test[categorical_columns])\n",
    "\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded.toarray(), columns=encoder.get_feature_names_out(categorical_columns))\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded.toarray(), columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "X_train.drop(categorical_columns, axis=1, inplace=True)\n",
    "X_test.drop(categorical_columns, axis=1, inplace=True)\n",
    "\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), X_test_encoded_df], axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train_encoded)\n",
    "y_test_categorical = to_categorical(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa23ceac-3c19-40b8-9d1a-b37a8f84a327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "MinMaxScaler best params: {'logisticregression__C': 100, 'logisticregression__class_weight': None, 'logisticregression__max_iter': 100, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'sag'}\n",
      "MinMaxScaler accuracy: 0.8022284122562674\n",
      "MinMaxScaler best score: 0.8044714833000594\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.80      0.79      0.80       526\n",
      "       Horde       0.81      0.81      0.81       551\n",
      "\n",
      "    accuracy                           0.80      1077\n",
      "   macro avg       0.80      0.80      0.80      1077\n",
      "weighted avg       0.80      0.80      0.80      1077\n",
      "\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.81      0.81      0.81      2153\n",
      "       Horde       0.81      0.81      0.81      2153\n",
      "\n",
      "    accuracy                           0.81      4306\n",
      "   macro avg       0.81      0.81      0.81      4306\n",
      "weighted avg       0.81      0.81      0.81      4306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_minmax = make_pipeline(MinMaxScaler(), LogisticRegression())\n",
    "param_grid_minmax = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logisticregression__penalty': ['l2'],\n",
    "    'logisticregression__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'logisticregression__max_iter': [1000, 2000, 3000],\n",
    "    'logisticregression__class_weight': [None, 'balanced'],\n",
    "}\n",
    "grid_search_minmax = GridSearchCV(pipeline_minmax, param_grid_minmax, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search_minmax.fit(X_train, y_train_encoded)\n",
    "y_pred_minmax = grid_search_minmax.predict(X_test)\n",
    "y_train_pred_minmax = grid_search_minmax.predict(X_train)\n",
    "accuracy_minmax = accuracy_score(y_test_encoded, y_pred_minmax)\n",
    "\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_minmax)\n",
    "y_train_labels = label_encoder.inverse_transform(y_train_encoded)\n",
    "y_train_pred_labels = label_encoder.inverse_transform(y_train_pred_minmax)\n",
    "\n",
    "print(\"MinMaxScaler best params:\", grid_search_minmax.best_params_)\n",
    "print(\"MinMaxScaler accuracy:\", accuracy_minmax)\n",
    "print(\"MinMaxScaler best score:\", grid_search_minmax.best_score_)\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train_labels, y_train_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f246e55a-782e-422f-bce6-d828fa8810cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "StandardScaler best params: {'logisticregression__C': 10, 'logisticregression__class_weight': None, 'logisticregression__max_iter': 100, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "StandardScaler accuracy: 0.8031569173630455\n",
      "StandardScaler best score: 0.8044714833000594\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.80      0.79      0.80       526\n",
      "       Horde       0.81      0.81      0.81       551\n",
      "\n",
      "    accuracy                           0.80      1077\n",
      "   macro avg       0.80      0.80      0.80      1077\n",
      "weighted avg       0.80      0.80      0.80      1077\n",
      "\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.81      0.81      0.81      2153\n",
      "       Horde       0.81      0.81      0.81      2153\n",
      "\n",
      "    accuracy                           0.81      4306\n",
      "   macro avg       0.81      0.81      0.81      4306\n",
      "weighted avg       0.81      0.81      0.81      4306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_standard = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "param_grid_standard = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logisticregression__penalty': ['l2'],\n",
    "    'logisticregression__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'logisticregression__max_iter': [1000, 2000, 3000],\n",
    "    'logisticregression__class_weight': [None, 'balanced'],\n",
    "}\n",
    "grid_search_standard = GridSearchCV(pipeline_standard, param_grid_standard, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search_standard.fit(X_train, y_train_encoded)\n",
    "y_pred_standard = grid_search_standard.predict(X_test)\n",
    "y_train_pred_standard = grid_search_standard.predict(X_train)\n",
    "accuracy_standard = accuracy_score(y_test_encoded, y_pred_standard)\n",
    "\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_standard)\n",
    "y_train_labels = label_encoder.inverse_transform(y_train_encoded)\n",
    "y_train_pred_labels = label_encoder.inverse_transform(y_train_pred_standard)\n",
    "\n",
    "print(\"StandardScaler best params:\", grid_search_standard.best_params_)\n",
    "print(\"StandardScaler accuracy:\", accuracy_standard)\n",
    "print(\"StandardScaler best score:\", grid_search_standard.best_score_)\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train_labels, y_train_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee967cde-dc1c-4dce-b4dd-d8c603696934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n",
      "DecisionTreeClassifier najlepsze parametry: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "DecisionTreeClassifier accuracy: 0.8458681522748375\n",
      "DecisionTreeClassifier best score: 0.8462639615820429\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.84      0.85      0.84       526\n",
      "       Horde       0.86      0.84      0.85       551\n",
      "\n",
      "    accuracy                           0.85      1077\n",
      "   macro avg       0.85      0.85      0.85      1077\n",
      "weighted avg       0.85      0.85      0.85      1077\n",
      "\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.92      0.93      0.93      2153\n",
      "       Horde       0.93      0.92      0.92      2153\n",
      "\n",
      "    accuracy                           0.93      4306\n",
      "   macro avg       0.93      0.93      0.93      4306\n",
      "weighted avg       0.93      0.93      0.93      4306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_decision_tree = {\n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'min_samples_leaf': [1, 8, 64],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid_decision_tree, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_test = grid_search.predict(X_test)\n",
    "y_pred_train = grid_search.predict(X_train)\n",
    "\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
    "y_train_labels = label_encoder.inverse_transform(y_train_encoded)\n",
    "y_pred_train_labels = label_encoder.inverse_transform(y_pred_train)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_test_labels)\n",
    "\n",
    "print(\"DecisionTreeClassifier najlepsze parametry:\", grid_search.best_params_)\n",
    "print(\"DecisionTreeClassifier accuracy:\", accuracy)\n",
    "print(\"DecisionTreeClassifier best score:\", grid_search.best_score_)\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test_labels, y_pred_test_labels))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train_labels, y_pred_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d567ccc9-1e7d-4b4c-92ca-0f112150fed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 324 candidates, totalling 3240 fits\n",
      "GradientBoostingClassifier best params: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "GradientBoostingClassifier accuracy: 0.8746518105849582\n",
      "GradientBoostingClassifier best score: 0.8794803863378838\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.89      0.85      0.87       526\n",
      "       Horde       0.86      0.90      0.88       551\n",
      "\n",
      "    accuracy                           0.87      1077\n",
      "   macro avg       0.88      0.87      0.87      1077\n",
      "weighted avg       0.88      0.87      0.87      1077\n",
      "\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       1.00      1.00      1.00      2153\n",
      "       Horde       1.00      1.00      1.00      2153\n",
      "\n",
      "    accuracy                           1.00      4306\n",
      "   macro avg       1.00      1.00      1.00      4306\n",
      "weighted avg       1.00      1.00      1.00      4306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_gradient_boosting = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'min_samples_leaf': [1, 8, 64],     \n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(gradient_boosting, param_grid_gradient_boosting, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_test = grid_search.predict(X_test)\n",
    "y_pred_train = grid_search.predict(X_train)\n",
    "\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
    "y_train_labels = label_encoder.inverse_transform(y_train_encoded)\n",
    "y_pred_train_labels = label_encoder.inverse_transform(y_pred_train)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_test_labels)\n",
    "\n",
    "print(\"GradientBoostingClassifier best params:\", grid_search.best_params_)\n",
    "print(\"GradientBoostingClassifier accuracy:\", accuracy)\n",
    "print(\"GradientBoostingClassifier best score:\", grid_search.best_score_)\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test_labels, y_pred_test_labels))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train_labels, y_pred_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8df92f4-56f5-451b-84fd-e011b9abc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 324 candidates, totalling 3240 fits\n",
      "RandomForestClassifier best params: {'max_depth': 30, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForestClassifier accuracy: 0.8792943361188487\n",
      "RandomForestClassifier best score: 0.8755371499487401\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.90      0.84      0.87       526\n",
      "       Horde       0.86      0.91      0.89       551\n",
      "\n",
      "    accuracy                           0.88      1077\n",
      "   macro avg       0.88      0.88      0.88      1077\n",
      "weighted avg       0.88      0.88      0.88      1077\n",
      "\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       1.00      1.00      1.00      2153\n",
      "       Horde       1.00      1.00      1.00      2153\n",
      "\n",
      "    accuracy                           1.00      4306\n",
      "   macro avg       1.00      1.00      1.00      4306\n",
      "weighted avg       1.00      1.00      1.00      4306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid_random_forest = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'min_samples_leaf': [1, 8, 64],     \n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "}\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, param_grid_random_forest, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred_test = grid_search.predict(X_test)\n",
    "y_pred_train = grid_search.predict(X_train)\n",
    "\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test)\n",
    "y_train_labels = label_encoder.inverse_transform(y_train_encoded)\n",
    "y_pred_train_labels = label_encoder.inverse_transform(y_pred_train)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_test_labels)\n",
    "\n",
    "print(\"RandomForestClassifier best params:\", grid_search.best_params_)\n",
    "print(\"RandomForestClassifier accuracy:\", accuracy)\n",
    "print(\"RandomForestClassifier best score:\", grid_search.best_score_)\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test_labels, y_pred_test_labels))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train_labels, y_pred_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f097edb-f20d-42e3-922a-67e0973e131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_dir\\my_project\\tuner0.json\n",
      "Epoch 1/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5542 - loss: 0.8086 - val_accuracy: 0.6833 - val_loss: 0.5986\n",
      "Epoch 2/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6693 - loss: 0.6160 - val_accuracy: 0.7436 - val_loss: 0.5465\n",
      "Epoch 3/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.5791 - val_accuracy: 0.7680 - val_loss: 0.5083\n",
      "Epoch 4/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 0.5446 - val_accuracy: 0.7715 - val_loss: 0.4879\n",
      "Epoch 5/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7634 - loss: 0.5002 - val_accuracy: 0.7784 - val_loss: 0.4679\n",
      "Epoch 6/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.4932 - val_accuracy: 0.7923 - val_loss: 0.4463\n",
      "Epoch 7/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.4868 - val_accuracy: 0.7958 - val_loss: 0.4343\n",
      "Epoch 8/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7886 - loss: 0.4718 - val_accuracy: 0.8121 - val_loss: 0.4268\n",
      "Epoch 9/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7758 - loss: 0.4715 - val_accuracy: 0.8155 - val_loss: 0.4190\n",
      "Epoch 10/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4503 - val_accuracy: 0.8167 - val_loss: 0.4149\n",
      "Epoch 11/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4421 - val_accuracy: 0.8283 - val_loss: 0.4114\n",
      "Epoch 12/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7982 - loss: 0.4404 - val_accuracy: 0.8318 - val_loss: 0.4046\n",
      "Epoch 13/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.4176 - val_accuracy: 0.8376 - val_loss: 0.4022\n",
      "Epoch 14/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8080 - loss: 0.4532 - val_accuracy: 0.8364 - val_loss: 0.3981\n",
      "Epoch 15/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4141 - val_accuracy: 0.8376 - val_loss: 0.3977\n",
      "Epoch 16/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.4107 - val_accuracy: 0.8376 - val_loss: 0.3954\n",
      "Epoch 17/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4203 - val_accuracy: 0.8399 - val_loss: 0.3961\n",
      "Epoch 18/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4319 - val_accuracy: 0.8434 - val_loss: 0.3953\n",
      "Epoch 19/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.4017 - val_accuracy: 0.8445 - val_loss: 0.3928\n",
      "Epoch 20/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.4243 - val_accuracy: 0.8399 - val_loss: 0.3915\n",
      "Epoch 21/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.4051 - val_accuracy: 0.8422 - val_loss: 0.3902\n",
      "Epoch 22/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3888 - val_accuracy: 0.8422 - val_loss: 0.3872\n",
      "Epoch 23/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.4172 - val_accuracy: 0.8376 - val_loss: 0.3848\n",
      "Epoch 24/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.4090 - val_accuracy: 0.8457 - val_loss: 0.3833\n",
      "Epoch 25/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.4013 - val_accuracy: 0.8492 - val_loss: 0.3846\n",
      "Epoch 26/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.3983 - val_accuracy: 0.8445 - val_loss: 0.3864\n",
      "Epoch 27/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4087 - val_accuracy: 0.8445 - val_loss: 0.3874\n",
      "Epoch 28/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4046 - val_accuracy: 0.8434 - val_loss: 0.3848\n",
      "Epoch 29/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.4048 - val_accuracy: 0.8469 - val_loss: 0.3883\n",
      "Epoch 30/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3946 - val_accuracy: 0.8434 - val_loss: 0.3840\n",
      "Epoch 31/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.3934 - val_accuracy: 0.8341 - val_loss: 0.3865\n",
      "Epoch 32/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.4099 - val_accuracy: 0.8515 - val_loss: 0.3833\n",
      "Epoch 33/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.4082 - val_accuracy: 0.8503 - val_loss: 0.3832\n",
      "Epoch 34/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4000 - val_accuracy: 0.8469 - val_loss: 0.3821\n",
      "Epoch 35/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4029 - val_accuracy: 0.8515 - val_loss: 0.3835\n",
      "Epoch 36/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4091 - val_accuracy: 0.8434 - val_loss: 0.3831\n",
      "Epoch 37/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8182 - loss: 0.4245 - val_accuracy: 0.8469 - val_loss: 0.3820\n",
      "Epoch 38/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3924 - val_accuracy: 0.8434 - val_loss: 0.3835\n",
      "Epoch 39/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.4314 - val_accuracy: 0.8376 - val_loss: 0.3839\n",
      "Epoch 40/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4216 - val_accuracy: 0.8445 - val_loss: 0.3831\n",
      "Epoch 41/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.3898 - val_accuracy: 0.8434 - val_loss: 0.3847\n",
      "Epoch 42/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.4032 - val_accuracy: 0.8445 - val_loss: 0.3826\n",
      "Epoch 43/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.3910 - val_accuracy: 0.8434 - val_loss: 0.3803\n",
      "Epoch 44/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.4024 - val_accuracy: 0.8480 - val_loss: 0.3815\n",
      "Epoch 45/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.4126 - val_accuracy: 0.8411 - val_loss: 0.3823\n",
      "Epoch 46/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8301 - loss: 0.3980 - val_accuracy: 0.8492 - val_loss: 0.3807\n",
      "Epoch 47/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8237 - loss: 0.3976 - val_accuracy: 0.8515 - val_loss: 0.3817\n",
      "Epoch 48/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3912 - val_accuracy: 0.8492 - val_loss: 0.3781\n",
      "Epoch 49/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.3911 - val_accuracy: 0.8515 - val_loss: 0.3811\n",
      "Epoch 50/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.4047 - val_accuracy: 0.8469 - val_loss: 0.3818\n",
      "Epoch 51/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3873 - val_accuracy: 0.8503 - val_loss: 0.3784\n",
      "Epoch 52/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.3957 - val_accuracy: 0.8480 - val_loss: 0.3805\n",
      "Epoch 53/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3922 - val_accuracy: 0.8503 - val_loss: 0.3772\n",
      "Epoch 54/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.4021 - val_accuracy: 0.8480 - val_loss: 0.3783\n",
      "Epoch 55/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4177 - val_accuracy: 0.8457 - val_loss: 0.3824\n",
      "Epoch 56/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4013 - val_accuracy: 0.8515 - val_loss: 0.3818\n",
      "Epoch 57/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.3883 - val_accuracy: 0.8550 - val_loss: 0.3790\n",
      "Epoch 58/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.3807 - val_accuracy: 0.8527 - val_loss: 0.3805\n",
      "Epoch 59/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.4129 - val_accuracy: 0.8469 - val_loss: 0.3810\n",
      "Epoch 60/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3881 - val_accuracy: 0.8445 - val_loss: 0.3818\n",
      "Epoch 61/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.3824 - val_accuracy: 0.8503 - val_loss: 0.3821\n",
      "Epoch 62/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4017 - val_accuracy: 0.8492 - val_loss: 0.3797\n",
      "Epoch 63/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3833 - val_accuracy: 0.8515 - val_loss: 0.3836\n",
      "Epoch 64/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3797 - val_accuracy: 0.8457 - val_loss: 0.3775\n",
      "Epoch 65/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.4053 - val_accuracy: 0.8515 - val_loss: 0.3771\n",
      "Epoch 66/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.3832 - val_accuracy: 0.8457 - val_loss: 0.3807\n",
      "Epoch 67/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.4110 - val_accuracy: 0.8503 - val_loss: 0.3769\n",
      "Epoch 68/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3889 - val_accuracy: 0.8480 - val_loss: 0.3802\n",
      "Epoch 69/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.3965 - val_accuracy: 0.8596 - val_loss: 0.3783\n",
      "Epoch 70/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8489 - loss: 0.3922 - val_accuracy: 0.8469 - val_loss: 0.3780\n",
      "Epoch 71/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.4179 - val_accuracy: 0.8538 - val_loss: 0.3779\n",
      "Epoch 72/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.3777 - val_accuracy: 0.8538 - val_loss: 0.3793\n",
      "Epoch 73/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.3918 - val_accuracy: 0.8515 - val_loss: 0.3782\n",
      "Epoch 74/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.3965 - val_accuracy: 0.8515 - val_loss: 0.3773\n",
      "Epoch 75/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.3864 - val_accuracy: 0.8596 - val_loss: 0.3772\n",
      "Epoch 76/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3797 - val_accuracy: 0.8480 - val_loss: 0.3820\n",
      "Epoch 77/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3907 - val_accuracy: 0.8550 - val_loss: 0.3801\n",
      "Epoch 78/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8303 - loss: 0.4008 - val_accuracy: 0.8527 - val_loss: 0.3806\n",
      "Epoch 79/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.4060 - val_accuracy: 0.8492 - val_loss: 0.3799\n",
      "Epoch 80/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.3941 - val_accuracy: 0.8492 - val_loss: 0.3801\n",
      "Epoch 81/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.3645 - val_accuracy: 0.8561 - val_loss: 0.3810\n",
      "Epoch 82/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.4203 - val_accuracy: 0.8573 - val_loss: 0.3794\n",
      "Epoch 83/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3892 - val_accuracy: 0.8538 - val_loss: 0.3789\n",
      "Epoch 84/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8267 - loss: 0.4012 - val_accuracy: 0.8527 - val_loss: 0.3790\n",
      "Epoch 85/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8159 - loss: 0.4143 - val_accuracy: 0.8561 - val_loss: 0.3823\n",
      "Epoch 86/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3935 - val_accuracy: 0.8515 - val_loss: 0.3809\n",
      "Epoch 87/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.3824 - val_accuracy: 0.8515 - val_loss: 0.3829\n",
      "Epoch 88/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.4279 - val_accuracy: 0.8527 - val_loss: 0.3775\n",
      "Epoch 89/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.3745 - val_accuracy: 0.8573 - val_loss: 0.3767\n",
      "Epoch 90/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8366 - loss: 0.3820 - val_accuracy: 0.8503 - val_loss: 0.3772\n",
      "Epoch 91/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3871 - val_accuracy: 0.8573 - val_loss: 0.3808\n",
      "Epoch 92/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.3958 - val_accuracy: 0.8527 - val_loss: 0.3816\n",
      "Epoch 93/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8299 - loss: 0.4052 - val_accuracy: 0.8550 - val_loss: 0.3782\n",
      "Epoch 94/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.3981 - val_accuracy: 0.8469 - val_loss: 0.3808\n",
      "Epoch 95/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3814 - val_accuracy: 0.8527 - val_loss: 0.3776\n",
      "Epoch 96/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.3789 - val_accuracy: 0.8573 - val_loss: 0.3766\n",
      "Epoch 97/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.4098 - val_accuracy: 0.8469 - val_loss: 0.3791\n",
      "Epoch 98/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.3823 - val_accuracy: 0.8550 - val_loss: 0.3818\n",
      "Epoch 99/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.4033 - val_accuracy: 0.8608 - val_loss: 0.3787\n",
      "Epoch 100/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.4082 - val_accuracy: 0.8561 - val_loss: 0.3776\n",
      "Epoch 101/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.3790 - val_accuracy: 0.8608 - val_loss: 0.3784\n",
      "Epoch 102/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.3904 - val_accuracy: 0.8457 - val_loss: 0.3836\n",
      "Epoch 103/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3863 - val_accuracy: 0.8480 - val_loss: 0.3837\n",
      "Epoch 104/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8349 - loss: 0.3948 - val_accuracy: 0.8538 - val_loss: 0.3823\n",
      "Epoch 105/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8235 - loss: 0.4166 - val_accuracy: 0.8550 - val_loss: 0.3767\n",
      "Epoch 106/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8168 - loss: 0.3977 - val_accuracy: 0.8561 - val_loss: 0.3774\n",
      "Epoch 107/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8312 - loss: 0.4032 - val_accuracy: 0.8527 - val_loss: 0.3776\n",
      "Epoch 108/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8224 - loss: 0.3908 - val_accuracy: 0.8561 - val_loss: 0.3811\n",
      "Epoch 109/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8304 - loss: 0.4130 - val_accuracy: 0.8515 - val_loss: 0.3801\n",
      "Epoch 110/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.3993 - val_accuracy: 0.8585 - val_loss: 0.3825\n",
      "Epoch 111/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3865 - val_accuracy: 0.8608 - val_loss: 0.3794\n",
      "Epoch 112/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3928 - val_accuracy: 0.8561 - val_loss: 0.3795\n",
      "Epoch 113/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.3666 - val_accuracy: 0.8538 - val_loss: 0.3811\n",
      "Epoch 114/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.4102 - val_accuracy: 0.8596 - val_loss: 0.3774\n",
      "Epoch 115/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3933 - val_accuracy: 0.8492 - val_loss: 0.3787\n",
      "Epoch 116/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4157 - val_accuracy: 0.8538 - val_loss: 0.3776\n",
      "Epoch 117/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3826 - val_accuracy: 0.8550 - val_loss: 0.3795\n",
      "Epoch 118/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.3899 - val_accuracy: 0.8585 - val_loss: 0.3791\n",
      "Epoch 119/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.4106 - val_accuracy: 0.8561 - val_loss: 0.3786\n",
      "Epoch 120/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.3943 - val_accuracy: 0.8585 - val_loss: 0.3781\n",
      "Epoch 121/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.3987 - val_accuracy: 0.8619 - val_loss: 0.3777\n",
      "Epoch 122/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.3967 - val_accuracy: 0.8573 - val_loss: 0.3750\n",
      "Epoch 123/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4050 - val_accuracy: 0.8538 - val_loss: 0.3830\n",
      "Epoch 124/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.4005 - val_accuracy: 0.8561 - val_loss: 0.3797\n",
      "Epoch 125/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.4054 - val_accuracy: 0.8550 - val_loss: 0.3801\n",
      "Epoch 126/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.3859 - val_accuracy: 0.8585 - val_loss: 0.3821\n",
      "Epoch 127/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.3974 - val_accuracy: 0.8596 - val_loss: 0.3784\n",
      "Epoch 128/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8286 - loss: 0.4030 - val_accuracy: 0.8550 - val_loss: 0.3777\n",
      "Epoch 129/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.3948 - val_accuracy: 0.8631 - val_loss: 0.3793\n",
      "Epoch 130/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.3982 - val_accuracy: 0.8573 - val_loss: 0.3775\n",
      "Epoch 131/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4045 - val_accuracy: 0.8596 - val_loss: 0.3798\n",
      "Epoch 132/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3849 - val_accuracy: 0.8538 - val_loss: 0.3791\n",
      "Epoch 133/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3914 - val_accuracy: 0.8538 - val_loss: 0.3757\n",
      "Epoch 134/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.4033 - val_accuracy: 0.8608 - val_loss: 0.3768\n",
      "Epoch 135/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.4161 - val_accuracy: 0.8527 - val_loss: 0.3805\n",
      "Epoch 136/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.3974 - val_accuracy: 0.8596 - val_loss: 0.3772\n",
      "Epoch 137/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3863 - val_accuracy: 0.8503 - val_loss: 0.3782\n",
      "Epoch 138/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.3832 - val_accuracy: 0.8619 - val_loss: 0.3792\n",
      "Epoch 139/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.4026 - val_accuracy: 0.8527 - val_loss: 0.3820\n",
      "Epoch 140/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.4056 - val_accuracy: 0.8492 - val_loss: 0.3790\n",
      "Epoch 141/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3965 - val_accuracy: 0.8492 - val_loss: 0.3781\n",
      "Epoch 142/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.4018 - val_accuracy: 0.8550 - val_loss: 0.3822\n",
      "Epoch 143/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.4039 - val_accuracy: 0.8573 - val_loss: 0.3813\n",
      "Epoch 144/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8201 - loss: 0.4148 - val_accuracy: 0.8527 - val_loss: 0.3802\n",
      "Epoch 145/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3907 - val_accuracy: 0.8550 - val_loss: 0.3790\n",
      "Epoch 146/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.3869 - val_accuracy: 0.8538 - val_loss: 0.3829\n",
      "Epoch 147/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.3874 - val_accuracy: 0.8538 - val_loss: 0.3800\n",
      "Epoch 148/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.3849 - val_accuracy: 0.8550 - val_loss: 0.3782\n",
      "Epoch 149/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.3937 - val_accuracy: 0.8457 - val_loss: 0.3810\n",
      "Epoch 150/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.4162 - val_accuracy: 0.8480 - val_loss: 0.3773\n",
      "Epoch 151/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.3841 - val_accuracy: 0.8573 - val_loss: 0.3773\n",
      "Epoch 152/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.4079 - val_accuracy: 0.8573 - val_loss: 0.3779\n",
      "Epoch 153/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3996 - val_accuracy: 0.8608 - val_loss: 0.3780\n",
      "Epoch 154/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4122 - val_accuracy: 0.8527 - val_loss: 0.3775\n",
      "Epoch 155/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.3835 - val_accuracy: 0.8480 - val_loss: 0.3757\n",
      "Epoch 156/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.3808 - val_accuracy: 0.8573 - val_loss: 0.3786\n",
      "Epoch 157/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.3890 - val_accuracy: 0.8538 - val_loss: 0.3787\n",
      "Epoch 158/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.4103 - val_accuracy: 0.8596 - val_loss: 0.3773\n",
      "Epoch 159/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.3806 - val_accuracy: 0.8608 - val_loss: 0.3779\n",
      "Epoch 160/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.3862 - val_accuracy: 0.8503 - val_loss: 0.3802\n",
      "Epoch 161/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.3797 - val_accuracy: 0.8503 - val_loss: 0.3818\n",
      "Epoch 162/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3785 - val_accuracy: 0.8573 - val_loss: 0.3786\n",
      "Epoch 163/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.4115 - val_accuracy: 0.8515 - val_loss: 0.3794\n",
      "Epoch 164/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4189 - val_accuracy: 0.8538 - val_loss: 0.3760\n",
      "Epoch 165/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3804 - val_accuracy: 0.8561 - val_loss: 0.3777\n",
      "Epoch 166/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.3876 - val_accuracy: 0.8561 - val_loss: 0.3805\n",
      "Epoch 167/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3943 - val_accuracy: 0.8573 - val_loss: 0.3797\n",
      "Epoch 168/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.3893 - val_accuracy: 0.8457 - val_loss: 0.3777\n",
      "Epoch 169/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3994 - val_accuracy: 0.8527 - val_loss: 0.3807\n",
      "Epoch 170/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.3875 - val_accuracy: 0.8585 - val_loss: 0.3775\n",
      "Epoch 171/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.3921 - val_accuracy: 0.8561 - val_loss: 0.3785\n",
      "Epoch 172/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4006 - val_accuracy: 0.8480 - val_loss: 0.3791\n",
      "Epoch 173/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3924 - val_accuracy: 0.8527 - val_loss: 0.3790\n",
      "Epoch 174/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.4009 - val_accuracy: 0.8527 - val_loss: 0.3786\n",
      "Epoch 175/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3837 - val_accuracy: 0.8503 - val_loss: 0.3780\n",
      "Epoch 176/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3883 - val_accuracy: 0.8480 - val_loss: 0.3785\n",
      "Epoch 177/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.3959 - val_accuracy: 0.8480 - val_loss: 0.3813\n",
      "Epoch 178/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3957 - val_accuracy: 0.8527 - val_loss: 0.3796\n",
      "Epoch 179/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3873 - val_accuracy: 0.8538 - val_loss: 0.3777\n",
      "Epoch 180/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.3911 - val_accuracy: 0.8561 - val_loss: 0.3757\n",
      "Epoch 181/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8458 - loss: 0.3851 - val_accuracy: 0.8515 - val_loss: 0.3765\n",
      "Epoch 182/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3918 - val_accuracy: 0.8515 - val_loss: 0.3800\n",
      "Epoch 183/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3912 - val_accuracy: 0.8457 - val_loss: 0.3788\n",
      "Epoch 184/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.3818 - val_accuracy: 0.8561 - val_loss: 0.3763\n",
      "Epoch 185/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3884 - val_accuracy: 0.8492 - val_loss: 0.3779\n",
      "Epoch 186/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.4062 - val_accuracy: 0.8515 - val_loss: 0.3801\n",
      "Epoch 187/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.3980 - val_accuracy: 0.8515 - val_loss: 0.3767\n",
      "Epoch 188/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.3982 - val_accuracy: 0.8550 - val_loss: 0.3733\n",
      "Epoch 189/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.4091 - val_accuracy: 0.8515 - val_loss: 0.3791\n",
      "Epoch 190/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.3939 - val_accuracy: 0.8515 - val_loss: 0.3778\n",
      "Epoch 191/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.4091 - val_accuracy: 0.8550 - val_loss: 0.3776\n",
      "Epoch 192/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3839 - val_accuracy: 0.8585 - val_loss: 0.3769\n",
      "Epoch 193/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.4036 - val_accuracy: 0.8561 - val_loss: 0.3756\n",
      "Epoch 194/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.4063 - val_accuracy: 0.8538 - val_loss: 0.3772\n",
      "Epoch 195/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.4028 - val_accuracy: 0.8538 - val_loss: 0.3766\n",
      "Epoch 196/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3773 - val_accuracy: 0.8480 - val_loss: 0.3749\n",
      "Epoch 197/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8258 - loss: 0.3916 - val_accuracy: 0.8561 - val_loss: 0.3768\n",
      "Epoch 198/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.4059 - val_accuracy: 0.8527 - val_loss: 0.3804\n",
      "Epoch 199/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.3830 - val_accuracy: 0.8492 - val_loss: 0.3791\n",
      "Epoch 200/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.4014 - val_accuracy: 0.8538 - val_loss: 0.3787\n",
      "Epoch 201/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8365 - loss: 0.3759 - val_accuracy: 0.8503 - val_loss: 0.3810\n",
      "Epoch 202/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3720 - val_accuracy: 0.8538 - val_loss: 0.3830\n",
      "Epoch 203/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.4006 - val_accuracy: 0.8492 - val_loss: 0.3794\n",
      "Epoch 204/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3860 - val_accuracy: 0.8469 - val_loss: 0.3770\n",
      "Epoch 205/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.3995 - val_accuracy: 0.8527 - val_loss: 0.3789\n",
      "Epoch 206/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8380 - loss: 0.3868 - val_accuracy: 0.8515 - val_loss: 0.3795\n",
      "Epoch 207/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.4083 - val_accuracy: 0.8469 - val_loss: 0.3775\n",
      "Epoch 208/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.4112 - val_accuracy: 0.8480 - val_loss: 0.3799\n",
      "Epoch 209/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3782 - val_accuracy: 0.8550 - val_loss: 0.3784\n",
      "Epoch 210/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.3741 - val_accuracy: 0.8469 - val_loss: 0.3833\n",
      "Epoch 211/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3814 - val_accuracy: 0.8561 - val_loss: 0.3817\n",
      "Epoch 212/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8317 - loss: 0.3893 - val_accuracy: 0.8434 - val_loss: 0.3805\n",
      "Epoch 213/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.3959 - val_accuracy: 0.8469 - val_loss: 0.3802\n",
      "Epoch 214/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3952 - val_accuracy: 0.8492 - val_loss: 0.3795\n",
      "Epoch 215/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.4091 - val_accuracy: 0.8515 - val_loss: 0.3805\n",
      "Epoch 216/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.3882 - val_accuracy: 0.8480 - val_loss: 0.3781\n",
      "Epoch 217/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3881 - val_accuracy: 0.8585 - val_loss: 0.3804\n",
      "Epoch 218/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3892 - val_accuracy: 0.8492 - val_loss: 0.3798\n",
      "Epoch 219/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.3937 - val_accuracy: 0.8469 - val_loss: 0.3777\n",
      "Epoch 220/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.3784 - val_accuracy: 0.8387 - val_loss: 0.3783\n",
      "Epoch 221/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.3921 - val_accuracy: 0.8515 - val_loss: 0.3780\n",
      "Epoch 222/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.3964 - val_accuracy: 0.8527 - val_loss: 0.3839\n",
      "Epoch 223/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.4010 - val_accuracy: 0.8550 - val_loss: 0.3802\n",
      "Epoch 224/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.3979 - val_accuracy: 0.8561 - val_loss: 0.3791\n",
      "Epoch 225/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.4202 - val_accuracy: 0.8608 - val_loss: 0.3780\n",
      "Epoch 226/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.3790 - val_accuracy: 0.8573 - val_loss: 0.3792\n",
      "Epoch 227/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.4053 - val_accuracy: 0.8550 - val_loss: 0.3799\n",
      "Epoch 228/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3919 - val_accuracy: 0.8515 - val_loss: 0.3776\n",
      "Epoch 229/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.3851 - val_accuracy: 0.8503 - val_loss: 0.3774\n",
      "Epoch 230/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.4041 - val_accuracy: 0.8550 - val_loss: 0.3794\n",
      "Epoch 231/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.3806 - val_accuracy: 0.8515 - val_loss: 0.3790\n",
      "Epoch 232/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.3787 - val_accuracy: 0.8550 - val_loss: 0.3795\n",
      "Epoch 233/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.3907 - val_accuracy: 0.8515 - val_loss: 0.3782\n",
      "Epoch 234/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8374 - loss: 0.3766 - val_accuracy: 0.8550 - val_loss: 0.3797\n",
      "Epoch 235/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3711 - val_accuracy: 0.8527 - val_loss: 0.3785\n",
      "Epoch 236/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.3941 - val_accuracy: 0.8538 - val_loss: 0.3799\n",
      "Epoch 237/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.4010 - val_accuracy: 0.8538 - val_loss: 0.3800\n",
      "Epoch 238/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.3920 - val_accuracy: 0.8550 - val_loss: 0.3798\n",
      "Epoch 239/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3812 - val_accuracy: 0.8492 - val_loss: 0.3773\n",
      "Epoch 240/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.4059 - val_accuracy: 0.8538 - val_loss: 0.3784\n",
      "Epoch 241/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.4135 - val_accuracy: 0.8480 - val_loss: 0.3794\n",
      "Epoch 242/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8312 - loss: 0.4046 - val_accuracy: 0.8480 - val_loss: 0.3789\n",
      "Epoch 243/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.3764 - val_accuracy: 0.8515 - val_loss: 0.3788\n",
      "Epoch 244/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8430 - loss: 0.3801 - val_accuracy: 0.8480 - val_loss: 0.3824\n",
      "Epoch 245/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.4091 - val_accuracy: 0.8503 - val_loss: 0.3765\n",
      "Epoch 246/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.3952 - val_accuracy: 0.8434 - val_loss: 0.3808\n",
      "Epoch 247/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3863 - val_accuracy: 0.8538 - val_loss: 0.3806\n",
      "Epoch 248/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3951 - val_accuracy: 0.8492 - val_loss: 0.3823\n",
      "Epoch 249/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.3736 - val_accuracy: 0.8538 - val_loss: 0.3780\n",
      "Epoch 250/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8424 - loss: 0.3772 - val_accuracy: 0.8515 - val_loss: 0.3804\n",
      "Epoch 251/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8317 - loss: 0.3900 - val_accuracy: 0.8492 - val_loss: 0.3826\n",
      "Epoch 252/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.3987 - val_accuracy: 0.8457 - val_loss: 0.3821\n",
      "Epoch 253/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.3809 - val_accuracy: 0.8492 - val_loss: 0.3782\n",
      "Epoch 254/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8299 - loss: 0.3980 - val_accuracy: 0.8422 - val_loss: 0.3791\n",
      "Epoch 255/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3931 - val_accuracy: 0.8503 - val_loss: 0.3790\n",
      "Epoch 256/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.3864 - val_accuracy: 0.8538 - val_loss: 0.3805\n",
      "Epoch 257/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.3854 - val_accuracy: 0.8515 - val_loss: 0.3813\n",
      "Epoch 258/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4053 - val_accuracy: 0.8608 - val_loss: 0.3767\n",
      "Epoch 259/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3723 - val_accuracy: 0.8550 - val_loss: 0.3791\n",
      "Epoch 260/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.3883 - val_accuracy: 0.8515 - val_loss: 0.3798\n",
      "Epoch 261/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3919 - val_accuracy: 0.8538 - val_loss: 0.3769\n",
      "Epoch 262/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3788 - val_accuracy: 0.8538 - val_loss: 0.3813\n",
      "Epoch 263/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.3894 - val_accuracy: 0.8492 - val_loss: 0.3789\n",
      "Epoch 264/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.3962 - val_accuracy: 0.8538 - val_loss: 0.3782\n",
      "Epoch 265/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.3877 - val_accuracy: 0.8550 - val_loss: 0.3809\n",
      "Epoch 266/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.3887 - val_accuracy: 0.8527 - val_loss: 0.3785\n",
      "Epoch 267/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3972 - val_accuracy: 0.8515 - val_loss: 0.3782\n",
      "Epoch 268/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.3823 - val_accuracy: 0.8515 - val_loss: 0.3785\n",
      "Epoch 269/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3848 - val_accuracy: 0.8527 - val_loss: 0.3792\n",
      "Epoch 270/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 0.3818 - val_accuracy: 0.8527 - val_loss: 0.3795\n",
      "Epoch 271/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.3923 - val_accuracy: 0.8515 - val_loss: 0.3782\n",
      "Epoch 272/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.3880 - val_accuracy: 0.8550 - val_loss: 0.3786\n",
      "Epoch 273/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.3877 - val_accuracy: 0.8515 - val_loss: 0.3800\n",
      "Epoch 274/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.3808 - val_accuracy: 0.8538 - val_loss: 0.3780\n",
      "Epoch 275/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.3987 - val_accuracy: 0.8538 - val_loss: 0.3780\n",
      "Epoch 276/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3926 - val_accuracy: 0.8469 - val_loss: 0.3789\n",
      "Epoch 277/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.3770 - val_accuracy: 0.8550 - val_loss: 0.3784\n",
      "Epoch 278/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.4183 - val_accuracy: 0.8503 - val_loss: 0.3780\n",
      "Epoch 279/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3852 - val_accuracy: 0.8503 - val_loss: 0.3766\n",
      "Epoch 280/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3949 - val_accuracy: 0.8527 - val_loss: 0.3780\n",
      "Epoch 281/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.3920 - val_accuracy: 0.8538 - val_loss: 0.3786\n",
      "Epoch 282/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3932 - val_accuracy: 0.8469 - val_loss: 0.3769\n",
      "Epoch 283/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3800 - val_accuracy: 0.8619 - val_loss: 0.3777\n",
      "Epoch 284/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.4002 - val_accuracy: 0.8573 - val_loss: 0.3769\n",
      "Epoch 285/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.3748 - val_accuracy: 0.8480 - val_loss: 0.3782\n",
      "Epoch 286/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3785 - val_accuracy: 0.8480 - val_loss: 0.3793\n",
      "Epoch 287/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.3991 - val_accuracy: 0.8503 - val_loss: 0.3773\n",
      "Epoch 288/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.3781 - val_accuracy: 0.8492 - val_loss: 0.3773\n",
      "Epoch 289/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3820 - val_accuracy: 0.8527 - val_loss: 0.3779\n",
      "Epoch 290/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.3935 - val_accuracy: 0.8527 - val_loss: 0.3784\n",
      "Epoch 291/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.3932 - val_accuracy: 0.8515 - val_loss: 0.3783\n",
      "Epoch 292/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8377 - loss: 0.3756 - val_accuracy: 0.8561 - val_loss: 0.3786\n",
      "Epoch 293/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.3890 - val_accuracy: 0.8527 - val_loss: 0.3772\n",
      "Epoch 294/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3884 - val_accuracy: 0.8561 - val_loss: 0.3759\n",
      "Epoch 295/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3942 - val_accuracy: 0.8538 - val_loss: 0.3762\n",
      "Epoch 296/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3866 - val_accuracy: 0.8527 - val_loss: 0.3773\n",
      "Epoch 297/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.4063 - val_accuracy: 0.8469 - val_loss: 0.3767\n",
      "Epoch 298/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3866 - val_accuracy: 0.8550 - val_loss: 0.3769\n",
      "Epoch 299/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.4016 - val_accuracy: 0.8480 - val_loss: 0.3782\n",
      "Epoch 300/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.3758 - val_accuracy: 0.8550 - val_loss: 0.3787\n",
      "Epoch 301/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.3867 - val_accuracy: 0.8538 - val_loss: 0.3777\n",
      "Epoch 302/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4064 - val_accuracy: 0.8480 - val_loss: 0.3768\n",
      "Epoch 303/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8295 - loss: 0.3976 - val_accuracy: 0.8527 - val_loss: 0.3796\n",
      "Epoch 304/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3786 - val_accuracy: 0.8503 - val_loss: 0.3771\n",
      "Epoch 305/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8474 - loss: 0.3832 - val_accuracy: 0.8527 - val_loss: 0.3789\n",
      "Epoch 306/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.3905 - val_accuracy: 0.8480 - val_loss: 0.3775\n",
      "Epoch 307/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.4015 - val_accuracy: 0.8538 - val_loss: 0.3773\n",
      "Epoch 308/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.3987 - val_accuracy: 0.8538 - val_loss: 0.3763\n",
      "Epoch 309/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.3724 - val_accuracy: 0.8538 - val_loss: 0.3755\n",
      "Epoch 310/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8430 - loss: 0.3945 - val_accuracy: 0.8538 - val_loss: 0.3761\n",
      "Epoch 311/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3924 - val_accuracy: 0.8492 - val_loss: 0.3762\n",
      "Epoch 312/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.3873 - val_accuracy: 0.8480 - val_loss: 0.3788\n",
      "Epoch 313/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.3861 - val_accuracy: 0.8515 - val_loss: 0.3785\n",
      "Epoch 314/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 0.3644 - val_accuracy: 0.8515 - val_loss: 0.3771\n",
      "Epoch 315/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3866 - val_accuracy: 0.8515 - val_loss: 0.3771\n",
      "Epoch 316/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3808 - val_accuracy: 0.8573 - val_loss: 0.3772\n",
      "Epoch 317/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.3929 - val_accuracy: 0.8527 - val_loss: 0.3768\n",
      "Epoch 318/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.4011 - val_accuracy: 0.8527 - val_loss: 0.3773\n",
      "Epoch 319/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.3930 - val_accuracy: 0.8503 - val_loss: 0.3745\n",
      "Epoch 320/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3824 - val_accuracy: 0.8527 - val_loss: 0.3763\n",
      "Epoch 321/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.4023 - val_accuracy: 0.8527 - val_loss: 0.3758\n",
      "Epoch 322/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.3962 - val_accuracy: 0.8573 - val_loss: 0.3766\n",
      "Epoch 323/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.4056 - val_accuracy: 0.8515 - val_loss: 0.3766\n",
      "Epoch 324/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3794 - val_accuracy: 0.8515 - val_loss: 0.3766\n",
      "Epoch 325/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.3859 - val_accuracy: 0.8538 - val_loss: 0.3769\n",
      "Epoch 326/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3859 - val_accuracy: 0.8515 - val_loss: 0.3785\n",
      "Epoch 327/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.4085 - val_accuracy: 0.8515 - val_loss: 0.3763\n",
      "Epoch 328/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.3747 - val_accuracy: 0.8527 - val_loss: 0.3781\n",
      "Epoch 329/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8311 - loss: 0.3822 - val_accuracy: 0.8469 - val_loss: 0.3772\n",
      "Epoch 330/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.3913 - val_accuracy: 0.8515 - val_loss: 0.3779\n",
      "Epoch 331/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.4016 - val_accuracy: 0.8561 - val_loss: 0.3775\n",
      "Epoch 332/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3877 - val_accuracy: 0.8550 - val_loss: 0.3787\n",
      "Epoch 333/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.3913 - val_accuracy: 0.8503 - val_loss: 0.3787\n",
      "Epoch 334/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.4009 - val_accuracy: 0.8469 - val_loss: 0.3765\n",
      "Epoch 335/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3806 - val_accuracy: 0.8480 - val_loss: 0.3777\n",
      "Epoch 336/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.3834 - val_accuracy: 0.8469 - val_loss: 0.3779\n",
      "Epoch 337/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.3926 - val_accuracy: 0.8527 - val_loss: 0.3773\n",
      "Epoch 338/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.3836 - val_accuracy: 0.8515 - val_loss: 0.3776\n",
      "Epoch 339/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3878 - val_accuracy: 0.8538 - val_loss: 0.3731\n",
      "Epoch 340/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3851 - val_accuracy: 0.8492 - val_loss: 0.3771\n",
      "Epoch 341/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.3812 - val_accuracy: 0.8527 - val_loss: 0.3764\n",
      "Epoch 342/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3888 - val_accuracy: 0.8550 - val_loss: 0.3771\n",
      "Epoch 343/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.3826 - val_accuracy: 0.8492 - val_loss: 0.3776\n",
      "Epoch 344/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4019 - val_accuracy: 0.8492 - val_loss: 0.3796\n",
      "Epoch 345/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3910 - val_accuracy: 0.8550 - val_loss: 0.3784\n",
      "Epoch 346/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8357 - loss: 0.3932 - val_accuracy: 0.8492 - val_loss: 0.3778\n",
      "Epoch 347/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8469 - loss: 0.3798 - val_accuracy: 0.8434 - val_loss: 0.3749\n",
      "Epoch 348/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3948 - val_accuracy: 0.8515 - val_loss: 0.3747\n",
      "Epoch 349/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3808 - val_accuracy: 0.8503 - val_loss: 0.3773\n",
      "Epoch 350/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8273 - loss: 0.3965 - val_accuracy: 0.8527 - val_loss: 0.3769\n",
      "Epoch 351/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4060 - val_accuracy: 0.8515 - val_loss: 0.3767\n",
      "Epoch 352/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3790 - val_accuracy: 0.8527 - val_loss: 0.3771\n",
      "Epoch 353/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.3892 - val_accuracy: 0.8503 - val_loss: 0.3759\n",
      "Epoch 354/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8474 - loss: 0.3783 - val_accuracy: 0.8492 - val_loss: 0.3765\n",
      "Epoch 355/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.3729 - val_accuracy: 0.8445 - val_loss: 0.3766\n",
      "Epoch 356/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3649 - val_accuracy: 0.8503 - val_loss: 0.3761\n",
      "Epoch 357/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.3769 - val_accuracy: 0.8538 - val_loss: 0.3771\n",
      "Epoch 358/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3744 - val_accuracy: 0.8480 - val_loss: 0.3763\n",
      "Epoch 359/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.3891 - val_accuracy: 0.8480 - val_loss: 0.3765\n",
      "Epoch 360/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: 0.3952 - val_accuracy: 0.8503 - val_loss: 0.3773\n",
      "Epoch 361/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8374 - loss: 0.3882 - val_accuracy: 0.8515 - val_loss: 0.3763\n",
      "Epoch 362/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.4223 - val_accuracy: 0.8550 - val_loss: 0.3753\n",
      "Epoch 363/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.3745 - val_accuracy: 0.8515 - val_loss: 0.3768\n",
      "Epoch 364/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.3806 - val_accuracy: 0.8527 - val_loss: 0.3752\n",
      "Epoch 365/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3812 - val_accuracy: 0.8492 - val_loss: 0.3753\n",
      "Epoch 366/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.3984 - val_accuracy: 0.8469 - val_loss: 0.3736\n",
      "Epoch 367/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3783 - val_accuracy: 0.8469 - val_loss: 0.3744\n",
      "Epoch 368/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.3845 - val_accuracy: 0.8492 - val_loss: 0.3749\n",
      "Epoch 369/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8313 - loss: 0.3967 - val_accuracy: 0.8457 - val_loss: 0.3771\n",
      "Epoch 370/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3959 - val_accuracy: 0.8422 - val_loss: 0.3780\n",
      "Epoch 371/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.3871 - val_accuracy: 0.8480 - val_loss: 0.3764\n",
      "Epoch 372/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3761 - val_accuracy: 0.8445 - val_loss: 0.3772\n",
      "Epoch 373/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.3877 - val_accuracy: 0.8457 - val_loss: 0.3765\n",
      "Epoch 374/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.3894 - val_accuracy: 0.8445 - val_loss: 0.3760\n",
      "Epoch 375/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3916 - val_accuracy: 0.8515 - val_loss: 0.3753\n",
      "Epoch 376/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3812 - val_accuracy: 0.8422 - val_loss: 0.3729\n",
      "Epoch 377/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.3977 - val_accuracy: 0.8480 - val_loss: 0.3742\n",
      "Epoch 378/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3830 - val_accuracy: 0.8469 - val_loss: 0.3746\n",
      "Epoch 379/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.3895 - val_accuracy: 0.8480 - val_loss: 0.3744\n",
      "Epoch 380/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3811 - val_accuracy: 0.8469 - val_loss: 0.3750\n",
      "Epoch 381/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8397 - loss: 0.3799 - val_accuracy: 0.8457 - val_loss: 0.3759\n",
      "Epoch 382/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.3901 - val_accuracy: 0.8434 - val_loss: 0.3739\n",
      "Epoch 383/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.3744 - val_accuracy: 0.8422 - val_loss: 0.3767\n",
      "Epoch 384/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.3755 - val_accuracy: 0.8445 - val_loss: 0.3775\n",
      "Epoch 385/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.3863 - val_accuracy: 0.8503 - val_loss: 0.3783\n",
      "Epoch 386/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8386 - loss: 0.3850 - val_accuracy: 0.8445 - val_loss: 0.3770\n",
      "Epoch 387/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8537 - loss: 0.3727 - val_accuracy: 0.8457 - val_loss: 0.3770\n",
      "Epoch 388/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3852 - val_accuracy: 0.8422 - val_loss: 0.3745\n",
      "Epoch 389/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8415 - loss: 0.3831 - val_accuracy: 0.8434 - val_loss: 0.3730\n",
      "Epoch 390/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.3886 - val_accuracy: 0.8445 - val_loss: 0.3750\n",
      "Epoch 391/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3874 - val_accuracy: 0.8469 - val_loss: 0.3737\n",
      "Epoch 392/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8359 - loss: 0.3789 - val_accuracy: 0.8469 - val_loss: 0.3742\n",
      "Epoch 393/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.3693 - val_accuracy: 0.8457 - val_loss: 0.3756\n",
      "Epoch 394/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3685 - val_accuracy: 0.8457 - val_loss: 0.3769\n",
      "Epoch 395/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.3680 - val_accuracy: 0.8492 - val_loss: 0.3747\n",
      "Epoch 396/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.3798 - val_accuracy: 0.8411 - val_loss: 0.3727\n",
      "Epoch 397/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.3764 - val_accuracy: 0.8445 - val_loss: 0.3726\n",
      "Epoch 398/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8426 - loss: 0.3774 - val_accuracy: 0.8469 - val_loss: 0.3736\n",
      "Epoch 399/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3985 - val_accuracy: 0.8503 - val_loss: 0.3752\n",
      "Epoch 400/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3965 - val_accuracy: 0.8480 - val_loss: 0.3756\n",
      "Epoch 401/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.3953 - val_accuracy: 0.8469 - val_loss: 0.3734\n",
      "Epoch 402/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.3841 - val_accuracy: 0.8469 - val_loss: 0.3736\n",
      "Epoch 403/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3742 - val_accuracy: 0.8469 - val_loss: 0.3751\n",
      "Epoch 404/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3739 - val_accuracy: 0.8434 - val_loss: 0.3767\n",
      "Epoch 405/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3881 - val_accuracy: 0.8515 - val_loss: 0.3771\n",
      "Epoch 406/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3743 - val_accuracy: 0.8480 - val_loss: 0.3737\n",
      "Epoch 407/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3763 - val_accuracy: 0.8457 - val_loss: 0.3743\n",
      "Epoch 408/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.3824 - val_accuracy: 0.8422 - val_loss: 0.3733\n",
      "Epoch 409/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8540 - loss: 0.3853 - val_accuracy: 0.8457 - val_loss: 0.3744\n",
      "Epoch 410/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3793 - val_accuracy: 0.8480 - val_loss: 0.3745\n",
      "Epoch 411/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8488 - loss: 0.3674 - val_accuracy: 0.8480 - val_loss: 0.3764\n",
      "Epoch 412/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.3859 - val_accuracy: 0.8445 - val_loss: 0.3719\n",
      "Epoch 413/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.3900 - val_accuracy: 0.8515 - val_loss: 0.3739\n",
      "Epoch 414/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.3988 - val_accuracy: 0.8469 - val_loss: 0.3742\n",
      "Epoch 415/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.3818 - val_accuracy: 0.8515 - val_loss: 0.3760\n",
      "Epoch 416/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3842 - val_accuracy: 0.8445 - val_loss: 0.3750\n",
      "Epoch 417/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.3848 - val_accuracy: 0.8480 - val_loss: 0.3731\n",
      "Epoch 418/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3598 - val_accuracy: 0.8515 - val_loss: 0.3750\n",
      "Epoch 419/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.3826 - val_accuracy: 0.8457 - val_loss: 0.3732\n",
      "Epoch 420/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.3875 - val_accuracy: 0.8469 - val_loss: 0.3740\n",
      "Epoch 421/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3831 - val_accuracy: 0.8492 - val_loss: 0.3735\n",
      "Epoch 422/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8337 - loss: 0.3824 - val_accuracy: 0.8492 - val_loss: 0.3735\n",
      "Epoch 423/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8487 - loss: 0.3902 - val_accuracy: 0.8469 - val_loss: 0.3738\n",
      "Epoch 424/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3766 - val_accuracy: 0.8434 - val_loss: 0.3751\n",
      "Epoch 425/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.3595 - val_accuracy: 0.8480 - val_loss: 0.3753\n",
      "Epoch 426/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.3973 - val_accuracy: 0.8422 - val_loss: 0.3744\n",
      "Epoch 427/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3837 - val_accuracy: 0.8434 - val_loss: 0.3750\n",
      "Epoch 428/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3698 - val_accuracy: 0.8480 - val_loss: 0.3743\n",
      "Epoch 429/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.3928 - val_accuracy: 0.8434 - val_loss: 0.3740\n",
      "Epoch 430/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3686 - val_accuracy: 0.8469 - val_loss: 0.3743\n",
      "Epoch 431/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4105 - val_accuracy: 0.8445 - val_loss: 0.3721\n",
      "Epoch 432/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3837 - val_accuracy: 0.8457 - val_loss: 0.3708\n",
      "Epoch 433/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3889 - val_accuracy: 0.8445 - val_loss: 0.3741\n",
      "Epoch 434/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.3659 - val_accuracy: 0.8434 - val_loss: 0.3747\n",
      "Epoch 435/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.3770 - val_accuracy: 0.8492 - val_loss: 0.3735\n",
      "Epoch 436/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.3914 - val_accuracy: 0.8527 - val_loss: 0.3744\n",
      "Epoch 437/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8432 - loss: 0.3794 - val_accuracy: 0.8503 - val_loss: 0.3780\n",
      "Epoch 438/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3746 - val_accuracy: 0.8422 - val_loss: 0.3741\n",
      "Epoch 439/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.3678 - val_accuracy: 0.8515 - val_loss: 0.3722\n",
      "Epoch 440/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8458 - loss: 0.3713 - val_accuracy: 0.8480 - val_loss: 0.3720\n",
      "Epoch 441/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3861 - val_accuracy: 0.8469 - val_loss: 0.3713\n",
      "Epoch 442/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3817 - val_accuracy: 0.8457 - val_loss: 0.3725\n",
      "Epoch 443/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3781 - val_accuracy: 0.8480 - val_loss: 0.3717\n",
      "Epoch 444/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3868 - val_accuracy: 0.8422 - val_loss: 0.3740\n",
      "Epoch 445/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3943 - val_accuracy: 0.8445 - val_loss: 0.3723\n",
      "Epoch 446/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3861 - val_accuracy: 0.8387 - val_loss: 0.3733\n",
      "Epoch 447/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8502 - loss: 0.3705 - val_accuracy: 0.8469 - val_loss: 0.3708\n",
      "Epoch 448/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3931 - val_accuracy: 0.8492 - val_loss: 0.3724\n",
      "Epoch 449/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3742 - val_accuracy: 0.8480 - val_loss: 0.3737\n",
      "Epoch 450/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3691 - val_accuracy: 0.8399 - val_loss: 0.3722\n",
      "Epoch 451/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.3710 - val_accuracy: 0.8480 - val_loss: 0.3722\n",
      "Epoch 452/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.3683 - val_accuracy: 0.8445 - val_loss: 0.3755\n",
      "Epoch 453/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3881 - val_accuracy: 0.8445 - val_loss: 0.3739\n",
      "Epoch 454/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.3882 - val_accuracy: 0.8434 - val_loss: 0.3740\n",
      "Epoch 455/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3848 - val_accuracy: 0.8457 - val_loss: 0.3743\n",
      "Epoch 456/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3813 - val_accuracy: 0.8469 - val_loss: 0.3718\n",
      "Epoch 457/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8479 - loss: 0.3905 - val_accuracy: 0.8469 - val_loss: 0.3722\n",
      "Epoch 458/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8374 - loss: 0.3764 - val_accuracy: 0.8538 - val_loss: 0.3725\n",
      "Epoch 459/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.3680 - val_accuracy: 0.8503 - val_loss: 0.3741\n",
      "Epoch 460/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3650 - val_accuracy: 0.8480 - val_loss: 0.3721\n",
      "Epoch 461/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3883 - val_accuracy: 0.8503 - val_loss: 0.3710\n",
      "Epoch 462/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.3996 - val_accuracy: 0.8492 - val_loss: 0.3688\n",
      "Epoch 463/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.3880 - val_accuracy: 0.8445 - val_loss: 0.3732\n",
      "Epoch 464/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3667 - val_accuracy: 0.8457 - val_loss: 0.3723\n",
      "Epoch 465/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3835 - val_accuracy: 0.8538 - val_loss: 0.3704\n",
      "Epoch 466/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.4019 - val_accuracy: 0.8550 - val_loss: 0.3716\n",
      "Epoch 467/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.3916 - val_accuracy: 0.8503 - val_loss: 0.3706\n",
      "Epoch 468/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8391 - loss: 0.3805 - val_accuracy: 0.8515 - val_loss: 0.3709\n",
      "Epoch 469/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.4052 - val_accuracy: 0.8503 - val_loss: 0.3715\n",
      "Epoch 470/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8437 - loss: 0.3781 - val_accuracy: 0.8480 - val_loss: 0.3719\n",
      "Epoch 471/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.3731 - val_accuracy: 0.8503 - val_loss: 0.3719\n",
      "Epoch 472/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.3862 - val_accuracy: 0.8445 - val_loss: 0.3743\n",
      "Epoch 473/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.3686 - val_accuracy: 0.8503 - val_loss: 0.3714\n",
      "Epoch 474/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3973 - val_accuracy: 0.8515 - val_loss: 0.3721\n",
      "Epoch 475/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8498 - loss: 0.3738 - val_accuracy: 0.8480 - val_loss: 0.3717\n",
      "Epoch 476/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.3889 - val_accuracy: 0.8469 - val_loss: 0.3714\n",
      "Epoch 477/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.3605 - val_accuracy: 0.8457 - val_loss: 0.3718\n",
      "Epoch 478/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.3685 - val_accuracy: 0.8480 - val_loss: 0.3721\n",
      "Epoch 479/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3617 - val_accuracy: 0.8469 - val_loss: 0.3711\n",
      "Epoch 480/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.3863 - val_accuracy: 0.8515 - val_loss: 0.3695\n",
      "Epoch 481/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.3955 - val_accuracy: 0.8492 - val_loss: 0.3717\n",
      "Epoch 482/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3764 - val_accuracy: 0.8538 - val_loss: 0.3724\n",
      "Epoch 483/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.3910 - val_accuracy: 0.8527 - val_loss: 0.3734\n",
      "Epoch 484/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8402 - loss: 0.3940 - val_accuracy: 0.8457 - val_loss: 0.3722\n",
      "Epoch 485/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8428 - loss: 0.3805 - val_accuracy: 0.8492 - val_loss: 0.3727\n",
      "Epoch 486/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.3823 - val_accuracy: 0.8527 - val_loss: 0.3734\n",
      "Epoch 487/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3821 - val_accuracy: 0.8585 - val_loss: 0.3730\n",
      "Epoch 488/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8444 - loss: 0.3779 - val_accuracy: 0.8527 - val_loss: 0.3726\n",
      "Epoch 489/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3709 - val_accuracy: 0.8480 - val_loss: 0.3744\n",
      "Epoch 490/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8398 - loss: 0.3774 - val_accuracy: 0.8503 - val_loss: 0.3718\n",
      "Epoch 491/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3953 - val_accuracy: 0.8538 - val_loss: 0.3703\n",
      "Epoch 492/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3775 - val_accuracy: 0.8434 - val_loss: 0.3718\n",
      "Epoch 493/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3907 - val_accuracy: 0.8492 - val_loss: 0.3712\n",
      "Epoch 494/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3742 - val_accuracy: 0.8469 - val_loss: 0.3729\n",
      "Epoch 495/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.3687 - val_accuracy: 0.8503 - val_loss: 0.3726\n",
      "Epoch 496/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.3924 - val_accuracy: 0.8527 - val_loss: 0.3712\n",
      "Epoch 497/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.3785 - val_accuracy: 0.8515 - val_loss: 0.3702\n",
      "Epoch 498/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3866 - val_accuracy: 0.8503 - val_loss: 0.3695\n",
      "Epoch 499/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.3825 - val_accuracy: 0.8469 - val_loss: 0.3726\n",
      "Epoch 500/500\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.3876 - val_accuracy: 0.8492 - val_loss: 0.3709\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Best parameters found:  {'neurons': 8, 'init': 'he_normal', 'dropout_rate': 0.1, 'optimizer': 'adam'}\n",
      "Test accuracy:  0.8337975858867224\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.85      0.81      0.83       526\n",
      "       Horde       0.82      0.86      0.84       551\n",
      "\n",
      "    accuracy                           0.83      1077\n",
      "   macro avg       0.83      0.83      0.83      1077\n",
      "weighted avg       0.83      0.83      0.83      1077\n",
      "\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Alliance       0.86      0.83      0.85      2153\n",
      "       Horde       0.84      0.87      0.85      2153\n",
      "\n",
      "    accuracy                           0.85      4306\n",
      "   macro avg       0.85      0.85      0.85      4306\n",
      "weighted avg       0.85      0.85      0.85      4306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units=hp.Int('neurons', min_value=1, max_value=10, step=1),\n",
    "                    kernel_initializer=hp.Choice('init', values=['glorot_uniform', 'he_normal']),\n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.0, max_value=0.2, step=0.1)))\n",
    "    model.add(Dense(len(label_encoder.classes_), kernel_initializer='glorot_uniform', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=hp.Choice('optimizer', values=['adam', 'SGD']),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=10,\n",
    "                        executions_per_trial=3,\n",
    "                        directory='keras_tuner_dir',\n",
    "                        project_name='my_project')\n",
    "\n",
    "tuner.search(X_train_scaled, y_train_categorical, epochs=500, validation_split=0.2)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "model = build_model(best_hps)\n",
    "\n",
    "epochs = best_hps.get('epochs') if 'epochs' in best_hps.values else 500\n",
    "batch_size = best_hps.get('batch_size') if 'batch_size' in best_hps.values else 10\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train_categorical, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "y_pred_test_encoded = model.predict(X_test_scaled)\n",
    "y_pred_train_encoded = model.predict(X_train_scaled)\n",
    "\n",
    "y_pred_test_num = np.argmax(y_pred_test_encoded, axis=1)\n",
    "y_pred_train_num = np.argmax(y_pred_train_encoded, axis=1)\n",
    "\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_test_labels = label_encoder.inverse_transform(y_pred_test_num)\n",
    "y_train_labels = label_encoder.inverse_transform(y_train_encoded)\n",
    "y_pred_train_labels = label_encoder.inverse_transform(y_pred_train_num)\n",
    "\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_test_labels)\n",
    "\n",
    "print(\"Best parameters found: \", best_hps.values)\n",
    "print(\"Test accuracy: \", accuracy)\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test_labels, y_pred_test_labels))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train_labels, y_pred_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169617e-ed49-4803-936c-242a202182ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
